name: CI-CD Pipeline

on:
    push:
        branches:
            - main
            - 'feature/*'
    pull_request:
        branches:
            - main
    workflow_dispatch:


jobs:
    build-and-push-image:
        runs-on: ubuntu-latest

        steps:
            - name: Checkout code
              uses: actions/checkout@v4

            - name: Get changed files
              id: changed-files-build
              uses: tj-actions/changed-files@v45
              with:
                    files: |
                        Dockerfile
                        requirements.txt
            - name: Set up Docker Buildx
              if: steps.changed-files-build.outputs.any_changed == 'true'
              uses: docker/setup-buildx-action@v3
            - name: Log in to DockerHub
              if: steps.changed-files-build.outputs.any_changed == 'true'
              uses: docker/login-action@v3
              with:
                username: ${{ vars.DOCKERHUB_USERNAME }}
                password: ${{ secrets.DOCKERHUB_PASSWORD }}

            - name: Build and push Docker image
              if: steps.changed-files-build.outputs.any_changed == 'true'
              run: |
                    docker buildx build --push \
                    --tag ${{ vars.DOCKERHUB_NAMESPACE }}/${{ vars.DOCKERHUB_REPOSITORY }}:latest \
                    --tag ${{ vars.DOCKERHUB_NAMESPACE }}/${{ vars.DOCKERHUB_REPOSITORY }}:${{ github.sha }} .
                
    unit-and-integration-and-e2e-tests:
        runs-on: ubuntu-latest
        needs: build-and-push-image
        env:
            AIRFLOW_WWW_USER_USERNAME: ${{ secrets.AIRFLOW_WWW_USER_USERNAME }}
            AIRFLOW_WWW_USER_PASSWORD: ${{ secrets.AIRFLOW_WWW_USER_PASSWORD }}
            API_KEY: ${{ secrets.API_KEY }}
            CELERY_BACKEND_NAME: ${{ secrets.CELERY_BACKEND_NAME }}
            CELERY_BACKEND_USERNAME: ${{ secrets.CELERY_BACKEND_USERNAME }}
            CELERY_BACKEND_PASSWORD: ${{ secrets.CELERY_BACKEND_PASSWORD }}
            ELT_DATABASE_NAME: ${{ secrets.ELT_DATABASE_NAME }}
            ELT_DATABASE_USERNAME: ${{ secrets.ELT_DATABASE_USERNAME }}
            ELT_DATABASE_PASSWORD: ${{ secrets.ELT_DATABASE_PASSWORD }}
            FERNET_KEY: ${{ secrets.FERNET_KEY }}
            METADATA_DATABASE_NAME: ${{ secrets.METADATA_DATABASE_NAME }}
            METADATA_DATABASE_USERNAME: ${{ secrets.METADATA_DATABASE_USERNAME }}
            METADATA_DATABASE_PASSWORD: ${{ secrets.METADATA_DATABASE_PASSWORD }}
            POSTGRES_USER: ${{ secrets.POSTGRES_USER }}
            POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
            POSTGRES_CONN_HOST: ${{ secrets.POSTGRES_CONN_HOST }}
            POSTGRES_CONN_PORT: ${{ secrets.POSTGRES_CONN_PORT }}
            POSTGRES_CONN_USERNAME: ${{ secrets.POSTGRES_CONN_USERNAME }}
            POSTGRES_CONN_PASSWORD: ${{ secrets.POSTGRES_CONN_PASSWORD }}
            AIRFLOW_UID: ${{ vars.AIRFLOW_UID }}
            CHANNEL_NAME: ${{ vars.CHANNEL_NAME }}
            DOCKER_USERNAME: ${{ vars.DOCKER_USERNAME }}
            DOCKERHUB_NAMESPACE: ${{ vars.DOCKER_NAMESPACE }}
            DOCKERHUB_REPOSITORY: ${{ vars.DOCKERHUB_REPOSITORY }}
        steps:
            - name: Checkout code
              uses: actions/checkout@v4
            - name: Get changed files
              id: changed-files-tests
              uses: tj-actions/changed-files@v45
              with:
                files: |
                    dags/**
                    include/**
                    docker-compose.yml
            - name: Set up Docker Compose
              if: steps.changed-files-tests.outputs.any_changed == 'true'
              run: docker compose up -d
            - name: Run unit and integration tests
              if: steps.changed-files-tests.outputs.any_changed == 'true'
              run: docker exec -t airflow-worker sh -c "pytest tests/ -v"
            - name: Run end-to-end DAG tests
              if: steps.changed-files-tests.outputs.any_changed == 'true'
              run: |
                DAG_NAMES=("youtube_video_stats_etl" "youtube_video_stats_dwh" "data_quality")
                for DAG_NAME in "${DAG_NAMES[@]}"; do
                  docker exec -t airflow-worker sh -c "airflow dags test $DAG_NAME 2024-01-01"
                done
            - name: Tear down Docker Compose
              if: steps.changed-files-tests.outputs.any_changed == 'true'
              run: docker compose down